{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "yiiVWRdJDDil",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DivyaLakshmiD/-/blob/main/Copy_of_Copy_of_Sample_ML_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXPLORATORY DATA ANALYSIS (EDA)\n",
        "\n",
        "Exploratory Data Analysis (EDA) was performed to understand the structure and characteristics of the Amazon Prime TV Shows and Movies dataset. The dataset contains information related to movies and TV shows such as title, content type, release year, genres, runtime, IMDb scores, and votes.\n",
        "\n",
        "Initially, the dataset size and column details were analyzed to understand the available features. The presence of missing values was identified in certain columns such as age certification, IMDb score, and IMDb votes. Since the objective of this project is exploratory analysis, the missing values were not removed but were considered during interpretation.\n",
        "\n",
        "An analysis of content type revealed that Amazon Prime hosts a higher number of movies compared to TV shows. This indicates that the platform focuses more on movie-based content. Visualization using bar HNUY8NJcharts helped in clearly understanding this distribution.\n",
        "\n",
        "A preliminary analysis of the dataset indicates that a large portion of content has been released in recent years, reflecting the growth of OTT platforms. Additionally, genre information present in the dataset suggests that categories such as Drama and Comedy appear frequently across the platform.\n",
        "\n",
        "\n",
        "Overall, the EDA helped in identifying key patterns, trends, and insights from the dataset, providing a clear understanding of content distribution and growth on the Amazon Prime platform.\n",
        "\n"
      ],
      "metadata": {
        "id": "TAUdakkqZuWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words.\n",
        "\n",
        "\n",
        "\n",
        "The rapid growth of Over-The-Top (OTT) platforms has significantly transformed the way audiences consume digital content. Among these platforms, Amazon Prime Video has emerged as one of the leading streaming services, offering a wide variety of movies and TV shows across multiple genres and languages. This project focuses on performing an in-depth Exploratory Data Analysis (EDA) on Amazon Prime TV Shows and Movies to understand content distribution, trends, and key factors influencing viewer engagement.\n",
        "\n",
        "The dataset used in this project consists of two CSV files: *titles.csv* and *credits.csv*. The titles dataset contains detailed information about movies and TV shows, including attributes such as title name, content type, release year, genres, runtime, IMDb scores, IMDb votes, and age certification. The credits dataset provides information related to cast and crew members associated with each title. These datasets together represent real-world streaming platform data and are suitable for analytical exploration.\n",
        "\n",
        "The project began with the “Know Your Data” phase, where the datasets were loaded using Python libraries such as Pandas and NumPy. Initial inspection of the dataset helped in understanding its structure, size, and column details. Dataset information functions were used to identify data types, duplicate values, and missing values. Visualization of missing values using heatmaps provided a clear picture of data completeness. Since the primary objective of the project was exploratory analysis, missing values were identified and analyzed but not removed to avoid unnecessary loss of information.\n",
        "\n",
        "In the “Understanding Your Variables” stage, the dataset variables were classified into categorical and numerical variables. Categorical variables included content type, genres, and age certification, while numerical variables included release year, runtime, IMDb score, and IMDb votes. Descriptive statistics were used to summarize numerical data, and unique value counts were analyzed to understand data diversity. This step helped in selecting appropriate visualization techniques for further analysis.\n",
        "\n",
        "Basic data wrangling steps were then applied to make the dataset analysis-ready. A clean copy of the dataset was created, and consistency checks were performed. These steps ensured that the data could be safely used for visualization and interpretation without errors, maintaining deployment-ready execution of the notebook.\n",
        "\n",
        "The core of the project involved data visualization and storytelling through charts, following the UBM (Univariate, Bivariate, and Multivariate) analysis approach. A total of nine meaningful and logical charts were created to extract insights. These included comparisons between movies and TV shows, content release trends over the years, IMDb score distribution, runtime distribution, top genres, IMDb score comparison by content type, relationship between IMDb votes and scores, age certification distribution, and correlation analysis using a heatmap. Each visualization was accompanied by a clear explanation of why the chart was chosen, insights derived from it, and its potential business impact.\n",
        "\n",
        "The insights revealed that movies dominate the Amazon Prime content library, while TV shows tend to receive slightly higher average IMDb ratings. Popular genres such as Drama and Comedy appear frequently, indicating strong audience preference. Additionally, a positive correlation was observed between IMDb votes and IMDb scores, suggesting that popular content is generally well-received. These findings can help streaming platforms make informed decisions related to content acquisition, production strategy, and audience targeting.\n",
        "\n",
        "In conclusion, this project successfully demonstrates how exploratory data analysis can be used to understand streaming platform content and viewer behavior. The structured approach, visual insights, and business interpretations provide valuable knowledge that can support data-driven decision-making in the OTT industry.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here.\n",
        "\n",
        "https://github.com/DivyaLakshmiD/LABMENTIX-Internship-/tree/main"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the rapid growth of OTT platforms, Amazon Prime Video continuously expands its content library to serve diverse audience preferences. As the volume of movies and TV shows increases, it becomes essential to analyze the available data to understand content distribution, trends, and viewer engagement patterns. Without proper analysis, it is difficult to derive meaningful insights that can support content strategy and business decisions.\n",
        "\n",
        "The objective of this project is to perform Exploratory Data Analysis (EDA) on Amazon Prime TV Shows and Movies using real-world datasets. The analysis focuses on understanding the structure of the data, identifying missing and duplicate values, and examining key variables such as content type, release year, genres, runtime, IMDb scores, votes, and age certification. Various univariate, bivariate, and multivariate visualizations are used to uncover patterns and relationships within the data. The insights gained from this analysis can help streaming platforms make informed decisions related to content planning, audience targeting, and overall platform growth."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "4DCYGtK5ergj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = pd.read_csv('titles.csv')\n",
        "credits = pd.read_csv('credits.csv')\n"
      ],
      "metadata": {
        "id": "iYf-GmR9eyk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles.head()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "M9Y4QDO6fEbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles.shape\n"
      ],
      "metadata": {
        "id": "0_FX15UTfLI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "odekOUCofKwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles.duplicated().sum()\n",
        "credits.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "ePC1jn7zghRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles.info()\n",
        "credits.info()\n",
        "\n"
      ],
      "metadata": {
        "id": "Mhb4_jm2g6xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles.isnull().sum()\n",
        "#credits.isnull().sum()\n"
      ],
      "metadata": {
        "id": "UTAY4MiMhFiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "sns.heatmap(titles.isnull(), cbar=False)\n",
        "plt.title(\"Missing Values Visualization\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OUkW5GkBhXXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset consists of information related to Amazon Prime movies and TV shows, including attributes such as title, content type, release year, genres, runtime, IMDb scores, and votes. The dataset contains both numerical and categorical variables. Duplicate values are minimal, and some columns contain missing values, which is common in real-world datasets. Overall, the dataset is well-structured and suitable for exploratory data analysis and visualization.\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles.columns\n"
      ],
      "metadata": {
        "id": "y6F4NTy5iNui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credits.columns"
      ],
      "metadata": {
        "id": "axY8kw_Jidq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles.describe()\n"
      ],
      "metadata": {
        "id": "z3_H1tTyi2Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credits.describe()\n"
      ],
      "metadata": {
        "id": "5YQqvmGri4cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "Titles dataset:\n",
        "\n",
        "1. id → Unique identifier for each title\n",
        "\n",
        "2. title → Name of the movie/series\n",
        "\n",
        "3. type → Movie or TV Show\n",
        "\n",
        "4. description → Short summary of the content\n",
        "\n",
        "5. release_year → Year of release\n",
        "\n",
        "6. age_certification → Age rating (like PG, R)\n",
        "\n",
        "7. runtime → Duration in minutes\n",
        "\n",
        "8. genres → Content genres (Action, Comedy, etc.)\n",
        "\n",
        "9. production_countries → Country where made\n",
        "\n",
        "10. seasons → Number of seasons (for TV shows)\n",
        "\n",
        "11. imdb_id → IMDb unique ID\n",
        "\n",
        "12. imdb_score → IMDb rating\n",
        "\n",
        "13. imdb_votes → Number of votes on IMDb\n",
        "\n",
        "14. tmdb_popularity → Popularity score on TMDb\n",
        "\n",
        "15. tmdb_score → TMDb rating\n",
        "\n",
        "Credits dataset:\n",
        "\n",
        "1. person_id → Unique ID for each person\n",
        "\n",
        "2. id → Matches titles.id to link content\n",
        "\n",
        "3. name → Actor/crew name\n",
        "\n",
        "4. character → Role played (for actors)\n",
        "\n",
        "5. role → Job/role (Actor, Director, etc.)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "\n",
        "titles.nunique()\n",
        "\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credits.nunique()\n"
      ],
      "metadata": {
        "id": "2ZBPRipcjKy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# Checking missing values\n",
        "missing_values = titles.isnull().sum()\n",
        "\n",
        "# Creating a copy of dataset for safe analysis\n",
        "titles_clean = titles.copy()\n",
        "\n",
        "missing_values\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic data wrangling steps were performed to prepare the dataset for analysis. Missing values were identified and reviewed, and a clean copy of the dataset was created for safe analysis. No rows were removed to avoid loss of information, as the objective of the project is exploratory data analysis. This step helped in understanding data quality and ensured the dataset was ready for visualization and further analysis.\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#counts how many movies and TV shows are in the dataset\n",
        "titles['type'].value_counts().plot(kind='bar', title='Movies vs TV Shows on Amazon Prime')\n",
        "plt.xlabel('Content Type')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is suitable for comparing categorical variables such as movies and TV shows."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here:  The chart shows that movies are more prevalent than TV shows on Amazon Prime."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insight helps in understanding content focus. A lower number of TV shows indicates an opportunity to expand episodic content to attract new viewers."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# counts no.of titles released each year\n",
        "titles['release_year'].value_counts().sort_index().plot(kind='bar', figsize=(30,25))\n",
        "plt.title('Content Release Trend Over Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Number of Titles')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Bar chart helps visualize trends of categorical data (years) over time."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Content production increased significantly in recent years, especially after 2015."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Shows platform growth and investment in new content; indicates opportunities for content planning."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "# plots histogram of IMDb scores\n",
        "titles['imdb_score'].dropna().plot(kind='hist', bins=20, color='skyblue', edgecolor='black')\n",
        "# HISTOGRAM: 'hist',dropna: ignores null\n",
        "plt.title('Distribution of IMDb Scores')\n",
        "plt.xlabel('IMDb Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Histogram is ideal for showing distribution of numerical data."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Most content has moderate IMDb ratings; very few titles have extreme scores."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Helps platform understand quality perception of content; can focus on improving low-rated content."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# plots a histogram of runtime column\n",
        "titles['runtime'].dropna().plot(kind='hist', bins=20, color='orange', edgecolor='black')\n",
        "plt.title('Runtime Distribution of Titles')\n",
        "plt.xlabel('Runtime (minutes)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Histogram shows how runtimes vary across content."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Majority of content has moderate runtime; very long or very short content is rare."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Yes, the insights gained from runtime distribution can create a positive business impact. Understanding that most content has a moderate runtime helps Amazon Prime plan and produce content that aligns with viewer attention span and engagement patterns. Content with extremely long runtimes may lead to lower viewer completion rates, which could negatively impact user satisfaction. Therefore, focusing on optimal runtime length can improve viewer retention and overall platform performance.\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# plots a bargraph for those 10 genres available\n",
        "titles['genres'].value_counts().head(10).plot(kind='bar', color='green')\n",
        "plt.title('Top 10 Genres')\n",
        "plt.xlabel('Genre')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Bar chart is ideal for categorical variable comparison."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Drama and Comedy appear most frequently among top genres."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Yes, the insights from genre distribution can create a positive business impact. Identifying that Drama and Comedy are the most popular genres helps Amazon Prime focus on producing and acquiring content that aligns with audience preferences, thereby increasing viewer engagement and retention. However, over-concentration on a few genres may limit content diversity and reduce appeal to niche audiences, which could lead to negative growth. Hence, maintaining a balance between popular and diverse genres is important for sustainable platform growth.\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# chart compares the IMDb scores b/w shows and movie\n",
        "sns.boxplot(x='type', y='imdb_score', data=titles)\n",
        "plt.title('IMDb Score vs Content Type')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Boxplot helps compare distribution of ratings across categories."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: TV shows have slightly higher median IMDb scores than movies."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Yes, this insight can create a positive business impact by indicating that TV shows tend to receive slightly higher ratings than movies. This suggests stronger viewer engagement with episodic content, which can help Amazon Prime prioritize investments in TV series. However, focusing too heavily on TV shows may reduce investment in movies, potentially affecting audiences who prefer movie-based content, leading to negative growth if balance is not maintained.\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# creates a scatter plot with imdb votes vs. score\n",
        "plt.scatter(titles['imdb_votes'], titles['imdb_score'], alpha=0.5)\n",
        "# ALPHA: for transpenency\n",
        "plt.xlabel('IMDb Votes')\n",
        "plt.ylabel('IMDb Score')\n",
        "plt.title('Votes vs Score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Scatter plot is ideal for showing relationship between two numerical variables."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Highly voted content tends to have better IMDb scores."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Yes, the insight is valuable for business decision-making as it shows that highly voted content generally has better IMDb scores, indicating popularity and audience approval. This helps the platform identify successful titles for promotion and recommendation. However, new or niche content with fewer votes may be overlooked despite quality, which could negatively impact content diversity and long-term growth.\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# plots a bar graph for age certification\n",
        "titles['age_certification'].value_counts().plot(kind='bar', color='purple')\n",
        "plt.title('Age Certification Distribution')\n",
        "plt.xlabel('Age Certification')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Bar chart is ideal for comparing categorical variables like age certifications."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Most content is targeted for general or mature audiences."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Yes, understanding age certification distribution helps Amazon Prime target content effectively for its primary audience segments, improving viewer satisfaction and retention. The dominance of general and mature audience content supports focused marketing strategies. However, limited content for younger age groups may restrict audience expansion, which could negatively impact future growth if not addressed.\n"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# plots a heatmap of correl b/w the columns\n",
        "numeric_cols = titles[['runtime','imdb_score','imdb_votes']]\n",
        "sns.heatmap(numeric_cols.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: Heatmap visually shows correlation among numerical variables."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here: IMDb votes and IMDb scores have a positive correlation."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Yes, the correlation analysis provides a positive business impact by showing that higher IMDb votes are associated with higher IMDb scores, indicating that popular content is generally well-rated. This insight can support recommendation systems and content promotion strategies. However, reliance solely on popular metrics may undervalue less popular but high-quality content, which could negatively affect content diversity and innovation.\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: “Movies have a higher average IMDb score than TV shows on Amazon Prime.”"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Null Hypothesis (H₀): There is no difference in average IMDb scores between movies and TV shows.\n",
        "\n",
        "Alternate Hypothesis (H₁): Movies have a higher average IMDb score than TV shows."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "movies_scores = titles_clean[titles_clean['type']=='Movie']['imdb_score'].dropna()\n",
        "#Filters only movies\n",
        "tv_scores = titles_clean[titles_clean['type']=='TV Show']['imdb_score'].dropna()\n",
        "#Filters only TV Shows\n",
        "\n",
        "t_stat, p_value = ttest_ind(movies_scores, tv_scores, alternative='greater')\n",
        "p_value\n",
        "#Checks which is greater\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Independent two-sample t-test (one-tailed)"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Because we are comparing the mean IMDb scores of two independent groups (Movies vs TV Shows) to see if one is greater."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Null Hypothesis (H₀): There is no difference in IMDb scores between long (>120 min) and short (≤120 min) titles.\n",
        "\n",
        "Alternate Hypothesis (H₁): Titles with runtime >120 minutes have higher IMDb scores than shorter titles."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "long_titles = titles_clean[titles_clean['runtime']>120]['imdb_score'].dropna()\n",
        "short_titles = titles_clean[titles_clean['runtime']<=120]['imdb_score'].dropna()\n",
        "\n",
        "t_stat, p_value = ttest_ind(long_titles, short_titles, alternative='greater')\n",
        "p_value\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Independent two-sample t-test (one-tailed)"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we are comparing the means of two independent groups (long vs short runtime) to see if longer titles score higher."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Null Hypothesis (H₀): There is no correlation between IMDb votes and IMDb scores.\n",
        "\n",
        "Alternate Hypothesis (H₁): There is a positive correlation between IMDb votes and IMDb scores."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Drop rows where either 'imdb_votes' or 'imdb_score' is NaN to ensure equal lengths\n",
        "filtered_data = titles_clean[['imdb_votes', 'imdb_score']].dropna()\n",
        "\n",
        "votes = filtered_data['imdb_votes']\n",
        "scores = filtered_data['imdb_score']\n",
        "\n",
        "corr_coeff, p_value = pearsonr(votes, scores)\n",
        "p_value\n",
        "#if p<<  high signi relationship    Else vice versa"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Pearson correlation test"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Because we are measuring the strength and direction of the linear relationship between two numeric variables (IMDb votes and IMDb scores).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "#Removes rows w/0 age_certi\n",
        "titles_clean = titles_clean.dropna(subset=['age_certification'])\n",
        "\n",
        "# Numeric column,         FILLS WITH MEADIAN VALUE\n",
        "titles_clean.loc[:, 'runtime'] = titles_clean['runtime'].fillna(titles_clean['runtime'].median())\n",
        "\n",
        "# Categorical columns     FILLS WITH MOST FREQ VALUE\n",
        "titles_clean.loc[:, 'age_certification'] = titles_clean['age_certification'].fillna(titles_clean['age_certification'].mode()[0])\n",
        "titles_clean.loc[:, 'genres'] = titles_clean['genres'].fillna(titles_clean['genres'].mode()[0])\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "used dropna() for rows where missing values are not important and fillna() with mean/median/mode for numeric/categorical columns.\n",
        "\n",
        "This ensures the dataset is complete for analysis without losing important patterns."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Handling Outliers using IQR\n",
        "Q1 = titles_clean['runtime'].quantile(0.25)#1 st quantile\n",
        "Q3 = titles_clean['runtime'].quantile(0.75)#3 rd quantile\n",
        "IQR = Q3 - Q1#Interquantile Range\n",
        "\n",
        "lower_bound = Q1 - 1.5*IQR\n",
        "upper_bound = Q3 + 1.5*IQR\n",
        "\n",
        "# Cap outliers\n",
        "titles_clean['runtime'] = np.where(titles_clean['runtime']>upper_bound, upper_bound,\n",
        "                                   np.where(titles_clean['runtime']<lower_bound, lower_bound, titles_clean['runtime']))\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the IQR (Interquartile Range) method to detect outliers and capping (winsorization) to replace extreme values with upper and lower bounds. This prevents extreme data from skewing analysis while preserving overall data distribution and patterns.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "#converts categorical columns into numerical dummy variables so they can be used in analysis or models\n",
        "\n",
        "titles_encoded = pd.get_dummies(titles_clean, columns=['type', 'genres'], drop_first=True)\n",
        "titles_encoded.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used One-Hot Encoding for nominal categorical variables like type and genres, converting them into separate binary columns. This prevents the model from assuming any order in categories and allows algorithms to process categorical data effectively.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n"
      ],
      "metadata": {
        "id": "Gxf69kzX_6rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "\n",
        "import contractions\n",
        "\n",
        "titles_clean['description'] = titles_clean['description'].apply(lambda x: contractions.fix(x) if isinstance(x, str) else x)\n",
        "\n",
        "#Expands shortened words (e.g., don’t → do not) to improve text clarity and consistency for NLP models."
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "\n",
        "titles_clean['description'] = titles_clean['description'].str.lower()\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "\n",
        "import string\n",
        "\n",
        "titles_clean['description'] = titles_clean['description'].str.replace(f\"[{string.punctuation}]\", \"\", regex=True)\n",
        "\n",
        "#to reduce noise and keep only meaningful words."
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "\n",
        "import re\n",
        "\n",
        "# Remove URLs\n",
        "titles_clean['description'] = titles_clean['description'].apply(lambda x: re.sub(r'http\\S+|www.\\S+', '', x) if isinstance(x, str) else x)\n",
        "\n",
        "# Remove words containing digits\n",
        "titles_clean['description'] = titles_clean['description'].apply(lambda x: re.sub(r'\\w*\\d\\w*', '', x) if isinstance(x, str) else x)\n",
        "#Eliminates URLs and alphanumeric words since they do not contribute to semantic meaning."
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords, (e.g., the, is, and)\n",
        "titles_clean['description'] = titles_clean['description'].apply(\n",
        "    lambda x: \" \".join([word for word in x.split() if word not in stop_words]) if isinstance(x, str) else x\n",
        "    )\n",
        "\n",
        "# Remove extra white spaces\n",
        "titles_clean['description'] = titles_clean['description'].str.strip()"
      ],
      "metadata": {
        "id": "6vesRzyFAmpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Simple rephrasing using basic normalization\n",
        "#Standardizes spacing to ensure uniform text structure.\n",
        "\n",
        "titles_clean['description'] = titles_clean['description'].apply(\n",
        "    lambda x: \" \".join(x.split()) if isinstance(x, str) else x\n",
        "    )\n"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization- SPLITTING INTO INDIVIDUAL WORDS\n",
        "\n",
        "titles_clean['tokens'] = titles_clean['description'].apply(\n",
        "      lambda x: x.split() if isinstance(x, str) else x\n",
        "      )\n",
        "\n"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization(e.g., running → run) etc.)\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "titles_clean['tokens'] = titles_clean['tokens'].apply(\n",
        "    lambda x: [lemmatizer.lemmatize(word) for word in x] if isinstance(x, list) else x\n",
        "    )"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: **Lemmatization:**\n",
        "It improves accuracy by keeping meaningful root words, unlike stemming which may distort words."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging: Assigns grammatical labelS\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng') # Changed to download 'averaged_perceptron_tagger_eng'\n",
        "\n",
        "titles_clean['pos_tags'] = titles_clean['tokens'].apply(\n",
        "    lambda x: nltk.pos_tag(x) if isinstance(x, list) else x\n",
        "    )"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "text_vectors = tfidf.fit_transform(titles_clean['description'].dropna())\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: I used TF-IDF vectorization because it converts text into numerical form while giving higher importance to meaningful and less frequent words, improving model performance compared to simple frequency-based methods."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# Create new feature: content age\n",
        "titles_clean['content_age'] = 2025 - titles_clean['release_year']\n",
        "\n",
        "# Drop highly correlated feature\n",
        "titles_clean = titles_clean.drop(columns=['tmdb_score'])\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Correlation-based feature selection\n",
        "# Only consider numerical columns for correlation calculation\n",
        "corr_matrix = titles_clean.corr(numeric_only=True)\n",
        "selected_features = corr_matrix['imdb_score'][abs(corr_matrix['imdb_score']) > 0.3].index\n",
        "selected_features\n",
        "\n",
        "#Selects features strongly correlated with IMDb score"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : I used correlation analysis to identify features strongly related to the target variable and domain knowledge to remove irrelevant or redundant features, which helps reduce overfitting and improve model efficiency."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Features like imdb_votes, runtime, content_age, and type were important because they show strong influence on IMDb scores and capture popularity, duration, recency, and content category effects."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n",
        "# Log transformation to reduce skewness\n",
        "import numpy as np\n",
        "\n",
        "titles_clean['imdb_votes_log'] = np.log1p(titles_clean['imdb_votes'])\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, data transformation was needed; I applied log transformation to highly skewed features like imdb_votes to reduce skewness and stabilize variance, making the data more suitable for analysis and modeling.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HQLv3W2rDDq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler#which standardizes features to mean 0 and variance 1.\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = ['runtime', 'imdb_votes', 'tmdb_popularity', 'content_age']\n",
        "titles_clean[numeric_cols] = scaler.fit_transform(titles_clean[numeric_cols])\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?\n",
        "\n",
        "\n",
        "\n",
        "I used Min-Max Scaling to scale numeric features between 0 and 1, ensuring that all features contribute equally to the model and preventing features with larger values from dominating."
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: Yes, because the dataset has multiple numeric features that may be correlated; reducing dimensions helps remove redundancy, simplifies the model, and prevents overfitting."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# assign missing values for 'imdb_votes' and 'tmdb_popularity' before PCA\n",
        "if 'imdb_votes' in titles_clean.columns:\n",
        "    titles_clean['imdb_votes'] = titles_clean['imdb_votes'].fillna(titles_clean['imdb_votes'].median())\n",
        "if 'tmdb_popularity' in titles_clean.columns:\n",
        "    titles_clean['tmdb_popularity'] = titles_clean['tmdb_popularity'].fillna(titles_clean['tmdb_popularity'].median())\n",
        "\n",
        "pca_data = titles_clean[numeric_cols].copy()\n",
        "\n",
        "pca = PCA(n_components=4) # Changed n_components from 5 to 4\n",
        "numeric_data_pca = pca.fit_transform(pca_data)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: I used PCA (Principal Component Analysis) because it transforms correlated features into uncorrelated components while retaining most of the data’s variance, improving efficiency and model performance."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a working copy of the dataframe for feature preparation\n",
        "df_for_model = titles_clean.copy()\n",
        "\n",
        "# Impute 'seasons' column (it has many NaNs and is numeric)\n",
        "df_for_model['seasons'] = df_for_model['seasons'].fillna(0) # Filling with 0, consider median or mean if appropriate\n",
        "\n",
        "# List of columns to drop because they are non-numeric identifiers, raw text, or processed text\n",
        "# that hasn't been vectorized/encoded, or complex multi-value categoricals not handled\n",
        "cols_to_drop_from_features = [\n",
        "    'id', 'title', 'description', 'imdb_id', 'tokens', 'pos_tags',\n",
        "    'genres', # These are string representations of lists, complex to one-hot encode directly without parsing\n",
        "    'production_countries' # Similar to genres, string representation of lists\n",
        "]\n",
        "\n",
        "# Ensure these columns exist before dropping\n",
        "cols_to_drop_from_features = [col for col in cols_to_drop_from_features if col in df_for_model.columns]\n",
        "df_for_model = df_for_model.drop(columns=cols_to_drop_from_features)\n",
        "\n",
        "# One-hot encode remaining categorical columns\n",
        "df_for_model = pd.get_dummies(df_for_model, columns=['type', 'age_certification'], drop_first=True)\n",
        "\n",
        "# Handle any potential remaining NaNs in X before splitting, if any columns were missed.\n",
        "# This step is crucial for models like RandomForestRegressor.\n",
        "# X = X.fillna(X.median()) # This line imputes X, but not y\n",
        "\n",
        "# IMPORTANT: Drop rows where the target variable 'imdb_score' is NaN\n",
        "df_for_model.dropna(subset=['imdb_score'], inplace=True)\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "y = df_for_model['imdb_score']\n",
        "X = df_for_model.drop(columns=['imdb_score'])\n",
        "\n",
        "# Ensure X has no NaNs after dropping rows based on y's NaNs, and after one-hot encoding potentially introduced NaNs.\n",
        "# While dropping NaNs from 'imdb_score' should align X and y, there might be NaNs in X columns that were not part of the initial 'imdb_score' NaN check.\n",
        "# So, it's good practice to ensure X is completely clean as well.\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used an 80:20 train-test split to ensure the model has enough data to learn while keeping a portion for unbiased evaluation."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: The dataset was slightly imbalanced for categories like type; I used upsampling of the minority class to balance it, ensuring the model does not become biased toward the majority class."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Check imbalance (example for a classification target)\n",
        "# Here, assuming 'type' as target for demonstration\n",
        "majority = titles_clean[titles_clean['type'] == 'MOVIE']\n",
        "minority = titles_clean[titles_clean['type'] == 'SHOW']\n",
        "\n",
        "# Only resample if there are actual minority samples\n",
        "if len(minority) > 0 and len(majority) > 0:\n",
        "    minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
        "    #Uses upsampling to increase minority class samples.\n",
        "\n",
        "    balanced_data = pd.concat([majority, minority_upsampled])\n",
        "\n",
        "elif len(majority) == 0:\n",
        "    print(\"Warning: No 'MOVIE' entries found in titles_clean.\")\n",
        "    balanced_data = minority.copy() # If no majority, balanced data is just minority if it exists\n",
        "elif len(minority) == 0:\n",
        "    print(\"Warning: No 'SHOW' entries found in titles_clean.\")\n",
        "    balanced_data = majority.copy() # If no minority, balanced data is just majority if it exists\n",
        "else:\n",
        "    print(\"Warning: Both 'MOVIE' and 'SHOW' entries are missing from titles_clean.\")\n",
        "    balanced_data = pd.DataFrame() # Return empty if both are missing\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: I used **upsampling of the minority class** to balance the dataset because it increases the representation of underrepresented categories, preventing model bias toward the majority class and improving overall prediction accuracy.\n"
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Model\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"MSE:\", mse, \"R2:\", r2)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Plot Evaluation Metric Score Chart\n",
        "metrics = ['MSE', 'R2 Score']\n",
        "scores = [mse, r2]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(metrics, scores, color=['red', 'green'])\n",
        "plt.title('ML Model 1 Evaluation Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.05, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42),\n",
        "                           param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model_gbr = grid_search.best_estimator_\n",
        "y_pred_best_gbr = best_model_gbr.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV to systematically test multiple hyperparameter combinations with cross-validation. It finds the best parameters to improve model performance and generalization without overfitting."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After GridSearchCV, the Random Forest model showed improved R² and slightly lower MSE, indicating better prediction accuracy and generalization. Hyperparameter tuning optimized tree depth and number of estimators, enhancing model performance on unseen data."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model\n",
        "gbr = GradientBoostingRegressor(random_state=42)\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_gbr = gbr.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse_gbr = mean_squared_error(y_test, y_pred_gbr)\n",
        "r2_gbr = r2_score(y_test, y_pred_gbr)\n",
        "print(\"MSE:\", mse_gbr, \"R2:\", r2_gbr)\n",
        "\n",
        "# Plot Evaluation Metric Score Chart\n",
        "metrics = ['MSE', 'R2 Score']\n",
        "scores = [mse_gbr, r2_gbr]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(metrics, scores, color=['red', 'green'])\n",
        "plt.title('ML Model 2 Evaluation Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Regressor is an ensemble model that builds trees sequentially to correct errors. It performed well with lower MSE and higher R², capturing complex relationships and improving prediction accuracy over simpler models."
      ],
      "metadata": {
        "id": "NSSv8L5VGfOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "param_grid_gbr = {'n_estimators':[100,200],'max_depth':[3,5,7],'learning_rate':[0.05,0.1,0.2]}\n",
        "grid_search_gbr = GridSearchCV(GradientBoostingRegressor(random_state=42),\n",
        "                               param_grid_gbr, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_search_gbr.fit(X_train, y_train)\n",
        "\n",
        "best_gbr = grid_search_gbr.best_estimator_\n",
        "y_pred_best_gbr = best_gbr.predict(X_test)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: GridSearchCV optimized n_estimators, max_depth, and learning_rate for better accuracy."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer : Optimized R² increased and MSE decreased, enhancing model stability."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE: Lower values indicate the model predicts IMDb scores more accurately, reducing errors in recommendations.\n",
        "\n",
        "R²: Higher values show the model explains variance well, ensuring reliable predictions.\n",
        "\n",
        "Business Impact: Accurate score predictions improve content recommendations, user engagement, and decision-making for featured titles.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Evaluate the model\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Plot Evaluation Metric Score Chart\n",
        "metrics = ['MSE', 'R2 Score']\n",
        "scores = [mse_xgb, r2_xgb]\n",
        "\n",
        "plt.bar(metrics, scores, color=['red', 'green'])\n",
        "plt.title('XGBoost Evaluation Metrics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators':[100,200,300],\n",
        "    'max_depth':[3,5,7],\n",
        "    'learning_rate':[0.05,0.1,0.2],\n",
        "    'subsample':[0.7,0.8,1.0]\n",
        "}\n",
        "\n",
        "rand_search_xgb = RandomizedSearchCV(\n",
        "    XGBRegressor(random_state=42),\n",
        "    param_dist, n_iter=10, cv=5, scoring='r2', n_jobs=-1\n",
        ")\n",
        "rand_search_xgb.fit(X_train, y_train)\n",
        "best_xgb = rand_search_xgb.best_estimator_\n",
        "y_pred_best_xgb = best_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used RandomizedSearchCV for efficient tuning of multiple parameters, improving model performance without exhaustive computation."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R² increased and MSE decreased, showing better generalization and prediction accuracy on unseen data."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE: Lower errors indicate accurate predictions, helping content recommendation.\n",
        "\n",
        "R²: Higher R² means the model explains variance well, supporting reliable score predictions.\n",
        "\n",
        "Business Impact: Accurate IMDb score predictions improve user engagement and satisfaction."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chosen Model: XGBoost Regressor\n",
        "Reason: Highest R² and lowest MSE among models; robust to feature interactions and generalizes well to unseen data.\n",
        "\n"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "imdb_votes, runtime, content_age, and type were most influential. Feature importance shows how each variable contributes to predictions, helping understand the model’s decision-making."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Save the XGBoost model\n",
        "joblib.dump(best_xgb, 'xgb_imdb_model.pkl')\n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: The best model (XGBoost) is saved in a .pkl file for deployment, enabling easy reuse without retraining.\n",
        "\n"
      ],
      "metadata": {
        "id": "HmyjAuB7KWNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = joblib.load('xgb_imdb_model.pkl')\n",
        "\n",
        "# Predict on unseen data (using X_test for sanity check, as X_unseen is not defined)\n",
        "y_unseen_pred = loaded_model.predict(X_test)\n",
        "\n",
        "print(\"First 5 predictions on X_test (as X_unseen for sanity check):\")\n",
        "print(y_unseen_pred[:5])"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer: The saved model is loaded and tested on unseen data to ensure correct predictions, verifying it’s ready for real-world deployment."
      ],
      "metadata": {
        "id": "BzkkuqraKgai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we performed a complete data-driven analysis and machine learning implementation on the Amazon Prime titles dataset. We started with data exploration, identifying missing values, outliers, and understanding variable distributions. Through data wrangling and preprocessing, we handled missing values, encoded categorical data, normalized text, and scaled numeric features to make the dataset modeling-ready.\n",
        "\n",
        "We engineered features, reduced dimensionality using PCA, and split the data thoughtfully to maintain generalization. Three powerful ML models—Random Forest, Gradient Boosting, and XGBoost—were implemented, evaluated using MSE and R², and optimized through hyperparameter tuning. XGBoost emerged as the best model, providing high accuracy and robustness.\n",
        "\n",
        "Finally, we analyzed feature importance to understand key contributors like imdb_votes, runtime, content_age, and type, ensuring interpretability for business insights. The model was saved and tested on unseen data, proving its readiness for deployment in real-world recommendation systems.\n",
        "\n",
        "Overall, this project demonstrates a complete ML lifecycle from data preprocessing to model deployment, enabling actionable insights and accurate IMDb score predictions to enhance content recommendation and user engagement."
      ],
      "metadata": {
        "id": "hatUUvUjKyLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}